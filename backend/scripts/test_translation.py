#!/usr/bin/env python3
"""
æµ‹è¯•æ®µè½ç¿»è¯‘åŠŸèƒ½
"""
import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.services.ai import GLMClient
from app.services.translation_engine import (
    SmartSegmenter,
    IncrementalTranslator
)


# æµ‹è¯•æ–‡æœ¬ï¼ˆåŒ…å«HTMLå’Œä»£ç å—ï¼‰
TEST_TEXT = """
<h1>æ·±åº¦å­¦ä¹ ç®€ä»‹</h1>

<p>æ·±åº¦å­¦ä¹ ï¼ˆDeep Learningï¼‰æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒåŸºäºäººå·¥ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ã€‚æ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚</p>

<h2>æ ¸å¿ƒæ¦‚å¿µ</h2>

<p>ç¥ç»ç½‘ç»œç”±å¤šä¸ªå±‚ç»„æˆï¼Œæ¯ä¸€å±‚éƒ½åŒ…å«è®¸å¤šç¥ç»å…ƒã€‚æ•°æ®ä»è¾“å…¥å±‚æµå‘è¾“å‡ºå±‚ï¼Œæ¯ä¸€å±‚éƒ½ä¼šå¯¹æ•°æ®è¿›è¡ŒæŸç§è½¬æ¢ã€‚</p>

<pre><code>
import torch
import torch.nn as nn

class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x
</code></pre>

<p>ä¸Šé¢çš„ä»£ç å±•ç¤ºäº†ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œå®ç°ã€‚è¿™ä¸ªç½‘ç»œæœ‰ä¸¤å±‚ï¼šç¬¬ä¸€å±‚æœ‰784ä¸ªè¾“å…¥å’Œ128ä¸ªè¾“å‡ºï¼Œç¬¬äºŒå±‚æœ‰128ä¸ªè¾“å…¥å’Œ10ä¸ªè¾“å‡ºã€‚</p>

<h2>è®­ç»ƒè¿‡ç¨‹</h2>

<p>è®­ç»ƒç¥ç»ç½‘ç»œéœ€è¦å¤§é‡çš„æ•°æ®å’Œè®¡ç®—èµ„æºã€‚è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬å‰å‘ä¼ æ’­ã€è®¡ç®—æŸå¤±ã€åå‘ä¼ æ’­å’Œå‚æ•°æ›´æ–°ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šé‡å¤è¿›è¡Œå¤šæ¬¡ï¼Œç›´åˆ°æ¨¡å‹è¾¾åˆ°æ»¡æ„çš„æ€§èƒ½ã€‚</p>

<p>ç°ä»£æ·±åº¦å­¦ä¹ æ¡†æ¶å¦‚PyTorchå’ŒTensorFlowå¤§å¤§ç®€åŒ–äº†è¿™ä¸ªè¿‡ç¨‹ã€‚å®ƒä»¬æä¾›äº†è‡ªåŠ¨å¾®åˆ†ã€GPUåŠ é€Ÿç­‰åŠŸèƒ½ï¼Œä½¿å¾—ç ”ç©¶äººå‘˜å¯ä»¥æ›´ä¸“æ³¨äºæ¨¡å‹è®¾è®¡è€Œä¸æ˜¯åº•å±‚å®ç°ã€‚</p>

<h2>åº”ç”¨é¢†åŸŸ</h2>

<ul>
<li>è®¡ç®—æœºè§†è§‰ï¼šå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²</li>
<li>è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆã€æƒ…æ„Ÿåˆ†æ</li>
<li>è¯­éŸ³è¯†åˆ«ï¼šè¯­éŸ³è½¬æ–‡å­—ã€è¯­éŸ³åˆæˆ</li>
<li>æ¨èç³»ç»Ÿï¼šä¸ªæ€§åŒ–æ¨èã€ååŒè¿‡æ»¤</li>
</ul>

<p>æ·±åº¦å­¦ä¹ å·²ç»æˆä¸ºäººå·¥æ™ºèƒ½é¢†åŸŸæœ€é‡è¦çš„æŠ€æœ¯ä¹‹ä¸€ï¼Œå¹¶ä¸”è¿˜åœ¨ä¸æ–­å‘å±•æ¼”è¿›ã€‚</p>
"""


async def test_smart_segmenter():
    """æµ‹è¯•æ™ºèƒ½åˆ†æ®µå™¨"""
    print("=" * 60)
    print("æµ‹è¯•1: æ™ºèƒ½æ®µè½åˆ†å‰²")
    print("=" * 60)
    
    segments = SmartSegmenter.split_by_paragraphs(
        TEST_TEXT,
        max_length=500
    )
    
    print(f"\nâœ… åˆ†å‰²ç»“æœ: {len(segments)} ä¸ªæ®µè½\n")
    
    for seg in segments:
        is_code_mark = "ğŸ“¦ [ä»£ç å—]" if seg['is_code'] else "ğŸ“ [æ–‡æœ¬]"
        content_preview = seg['content'][:80].replace('\n', ' ')
        print(f"{is_code_mark} æ®µè½ {seg['index']}")
        print(f"   é•¿åº¦: {len(seg['content'])} å­—ç¬¦")
        print(f"   å†…å®¹: {content_preview}...")
        print(f"   å“ˆå¸Œ: {seg['hash'][:8]}")
        print()


async def test_translation_with_mock():
    """ä½¿ç”¨æ¨¡æ‹Ÿå®¢æˆ·ç«¯æµ‹è¯•ç¿»è¯‘ï¼ˆä¸éœ€è¦çœŸå®APIï¼‰"""
    print("=" * 60)
    print("æµ‹è¯•2: æ¨¡æ‹Ÿç¿»è¯‘æµç¨‹ï¼ˆä¸è°ƒç”¨çœŸå®APIï¼‰")
    print("=" * 60)
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„GLMå®¢æˆ·ç«¯
    class MockGLMClient:
        async def translate(self, text, target_language='zh'):
            """æ¨¡æ‹Ÿç¿»è¯‘ - ç›´æ¥è¿”å›åŸæ–‡åŠ æ ‡è®°"""
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            return f"[å·²ç¿»è¯‘ä¸º{target_language}] {text[:50]}..."
    
    mock_client = MockGLMClient()
    translator = IncrementalTranslator(mock_client)
    
    # è¿›åº¦å›è°ƒ
    def progress_callback(current, total, message):
        percent = int((current / total) * 100)
        bar_length = 40
        filled = int(bar_length * current / total)
        bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)
        print(f"\rè¿›åº¦: [{bar}] {percent}% - {message}", end='', flush=True)
    
    print("\nå¼€å§‹ç¿»è¯‘...\n")
    
    result = await translator.translate_long_text(
        TEST_TEXT,
        target_language='zh',
        max_segment_length=500,
        max_concurrent=3,
        progress_callback=progress_callback
    )
    
    print("\n\nâœ… ç¿»è¯‘å®Œæˆ!")
    print(f"\nåŸæ–‡é•¿åº¦: {len(TEST_TEXT)} å­—ç¬¦")
    print(f"è¯‘æ–‡é•¿åº¦: {len(result)} å­—ç¬¦")
    print(f"\nç¼“å­˜ç»Ÿè®¡: {translator.get_cache_stats()}")
    
    print("\nè¯‘æ–‡é¢„è§ˆï¼ˆå‰200å­—ç¬¦ï¼‰:")
    print("-" * 60)
    print(result[:200])
    print("-" * 60)


async def test_translation_real():
    """ä½¿ç”¨çœŸå®APIæµ‹è¯•ç¿»è¯‘"""
    print("=" * 60)
    print("æµ‹è¯•3: çœŸå®APIç¿»è¯‘ï¼ˆéœ€è¦é…ç½®APIå¯†é’¥ï¼‰")
    print("=" * 60)
    
    # ä»ç¯å¢ƒå˜é‡è¯»å–APIé…ç½®
    import os
    
    api_key = os.getenv('GLM_API_KEY')
    base_url = os.getenv('GLM_BASE_URL', 'https://open.bigmodel.cn/api/paas/v4')
    model = os.getenv('GLM_MODEL', 'glm-4-flash')
    
    if not api_key:
        print("\nâš ï¸  è·³è¿‡çœŸå®APIæµ‹è¯•ï¼ˆæœªè®¾ç½® GLM_API_KEYï¼‰")
        print("æç¤º: è®¾ç½®ç¯å¢ƒå˜é‡åé‡è¯•:")
        print("  export GLM_API_KEY='your-api-key'")
        print("  export GLM_BASE_URL='https://open.bigmodel.cn/api/paas/v4'")
        print("  export GLM_MODEL='glm-4-flash'")
        return
    
    print(f"\nä½¿ç”¨é…ç½®:")
    print(f"  Model: {model}")
    print(f"  Base URL: {base_url}")
    print(f"  API Key: {api_key[:10]}...")
    
    client = GLMClient(
        api_key=api_key,
        base_url=base_url,
        model=model
    )
    
    translator = IncrementalTranslator(client)
    
    # ä½¿ç”¨è¾ƒçŸ­çš„æµ‹è¯•æ–‡æœ¬
    short_text = """
<h1>Introduction to Machine Learning</h1>

<p>Machine Learning is a subset of artificial intelligence that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.</p>

<p>There are three main types of machine learning: supervised learning, unsupervised learning, and reinforcement learning.</p>
"""
    
    def progress_callback(current, total, message):
        percent = int((current / total) * 100)
        print(f"è¿›åº¦: {percent}% - {message}")
    
    print("\nå¼€å§‹ç¿»è¯‘...\n")
    
    try:
        result = await translator.translate_long_text(
            short_text,
            target_language='zh',
            max_segment_length=300,
            max_concurrent=2,
            progress_callback=progress_callback
        )
        
        print("\nâœ… ç¿»è¯‘æˆåŠŸ!")
        print("\nè¯‘æ–‡:")
        print("=" * 60)
        print(result)
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ ç¿»è¯‘å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ æ®µè½ç¿»è¯‘åŠŸèƒ½æµ‹è¯•\n")
    
    # æµ‹è¯•1: æ®µè½åˆ†å‰²
    await test_smart_segmenter()
    
    # æµ‹è¯•2: æ¨¡æ‹Ÿç¿»è¯‘
    await test_translation_with_mock()
    
    # æµ‹è¯•3: çœŸå®APIï¼ˆå¯é€‰ï¼‰
    print("\n")
    choice = input("æ˜¯å¦æµ‹è¯•çœŸå®APIç¿»è¯‘ï¼Ÿ(y/N): ").lower()
    if choice == 'y':
        await test_translation_real()
    else:
        print("\nâ­ï¸  è·³è¿‡çœŸå®APIæµ‹è¯•")
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!\n")


if __name__ == "__main__":
    asyncio.run(main())








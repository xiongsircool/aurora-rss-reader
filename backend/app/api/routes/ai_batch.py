"""
Batch Translation API for Immersive Translation Feature.

This module provides a new endpoint for translating multiple text segments
in a single request, with caching support via the paragraph_map field.
"""
from __future__ import annotations

import hashlib
from typing import Optional
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from sqlmodel import select
from pydantic import BaseModel

from app.db.deps import get_session
from app.db.models import Entry, Translation
from app.services.ai import ai_client_manager
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/ai", tags=["ai"])


class TranslationSegment(BaseModel):
    """A single segment to translate."""
    id: str  # Block hash ID (generated by frontend)
    text: str  # Plain text content to translate


class BatchTranslationRequest(BaseModel):
    """Request body for batch translation."""
    entry_id: str
    language: str = "zh"
    segments: list[TranslationSegment]


class BatchTranslationResponse(BaseModel):
    """Response containing translated segments."""
    entry_id: str
    language: str
    results: dict[str, str]  # {block_id: translated_text}
    cached_count: int  # Number of segments retrieved from cache
    translated_count: int  # Number of segments freshly translated


@router.post("/translate-batch", response_model=BatchTranslationResponse)
async def translate_batch(
    payload: BatchTranslationRequest,
    session: AsyncSession = Depends(get_session)
) -> BatchTranslationResponse:
    """
    Translate multiple text segments in a batch.
    
    This endpoint:
    1. Checks the Translation.paragraph_map for cached translations.
    2. Translates only the missing segments.
    3. Updates the cache with new translations.
    4. Returns all requested translations (cached + new).
    """
    # Validate entry exists
    entry = await session.get(Entry, payload.entry_id)
    if not entry:
        raise HTTPException(status_code=404, detail="Entry not found")
    
    # Get or create Translation record
    result = await session.exec(
        select(Translation).where(
            Translation.entry_id == payload.entry_id,
            Translation.language == payload.language
        )
    )
    translation = result.first()
    
    if not translation:
        translation = Translation(
            entry_id=payload.entry_id,
            language=payload.language,
            paragraph_map={}
        )
        session.add(translation)
        await session.commit()
        await session.refresh(translation)
    
    # Initialize paragraph_map if None
    paragraph_map = translation.paragraph_map or {}
    
    # Separate cached and uncached segments
    results: dict[str, str] = {}
    segments_to_translate: list[TranslationSegment] = []
    cached_count = 0
    
    for segment in payload.segments:
        if segment.id in paragraph_map:
            # Use cached translation
            results[segment.id] = paragraph_map[segment.id]
            cached_count += 1
        else:
            # Need to translate this segment
            segments_to_translate.append(segment)
    
    # Translate uncached segments
    translated_count = 0
    if segments_to_translate:
        try:
            client = ai_client_manager.get_client("translation")
            
            # Batch translate - process segments in parallel-ish manner
            for segment in segments_to_translate:
                if not segment.text.strip():
                    # Skip empty segments
                    results[segment.id] = ""
                    translated_count += 1
                    continue
                
                try:
                    translated_text = await client.translate(
                        segment.text,
                        target_language=payload.language
                    )
                    results[segment.id] = translated_text
                    paragraph_map[segment.id] = translated_text
                    translated_count += 1
                except Exception as e:
                    logger.warning(f"Failed to translate segment {segment.id}: {e}")
                    # Mark as failed but continue with others
                    results[segment.id] = f"[Translation Error: {str(e)}]"
            
            # Update database with new translations
            translation.paragraph_map = paragraph_map
            session.add(translation)
            await session.commit()
            
        except Exception as e:
            logger.error(f"Batch translation failed: {e}")
            raise HTTPException(status_code=500, detail=f"Translation service error: {str(e)}")
    
    return BatchTranslationResponse(
        entry_id=payload.entry_id,
        language=payload.language,
        results=results,
        cached_count=cached_count,
        translated_count=translated_count
    )


@router.get("/translation-cache/{entry_id}")
async def get_translation_cache(
    entry_id: str,
    language: str = "zh",
    session: AsyncSession = Depends(get_session)
) -> dict:
    """
    Get cached translations for an entry.
    
    Returns the paragraph_map if available, allowing frontend to
    pre-populate translations without making translation requests.
    """
    result = await session.exec(
        select(Translation).where(
            Translation.entry_id == entry_id,
            Translation.language == language
        )
    )
    translation = result.first()
    
    if not translation:
        return {"entry_id": entry_id, "language": language, "paragraph_map": {}}
    
    return {
        "entry_id": entry_id,
        "language": language,
        "paragraph_map": translation.paragraph_map or {},
        "title": translation.title,
        "summary": translation.summary
    }
